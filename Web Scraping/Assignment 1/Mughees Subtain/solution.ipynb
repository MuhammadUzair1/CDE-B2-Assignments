{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1d190775",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b42cb776",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping page 1...\n",
      "Scraping page 2...\n",
      "Scraping page 3...\n",
      "Scraping page 4...\n",
      "Scraping page 5...\n",
      "Scraping page 6...\n",
      "Scraping page 7...\n",
      "Scraping page 8...\n",
      "Scraping page 9...\n",
      "Scraping complete. Total books collected: 450\n"
     ]
    }
   ],
   "source": [
    "# scrap \"Contemporary Fiction\" books from Thriftbooks\n",
    "dataAll = []\n",
    "\n",
    "with open('Thrift_books_Data.csv', 'w', encoding='utf-8') as f:\n",
    "    f.write('Title,Condition,Price\\n')\n",
    "\n",
    "    for page in range(1, 10):  \n",
    "        url = f\"https://www.thriftbooks.com/browse/?12667col#b.s=mostPopular-desc&b.p={page}&b.pp=50&b.col&b.f.t%5B%5D=12667&b.list\"\n",
    "\n",
    "        print(f\"Scraping page {page}...\")\n",
    "\n",
    "        content = requests.get(url).content\n",
    "        soup = BeautifulSoup(content, 'html.parser')\n",
    "\n",
    "        script_content = soup.find_all('script')\n",
    "       \n",
    "        data = script_content[12].string\n",
    "        match = re.search(r'window\\.searchStoreV2\\s*=\\s*(\\{.*?\\});', data, re.DOTALL)\n",
    "\n",
    "        if match:\n",
    "            json_data = match.group(1)\n",
    "            work_json = json.loads(json_data)\n",
    "\n",
    "            works = work_json.get('works', [])\n",
    "\n",
    "            for i in works:\n",
    "                item_data = {\n",
    "                    \"title\": i.get(\"title\"),\n",
    "                    \"condition\": i.get(\"buyNowCondition\"),\n",
    "                    \"price\": i.get(\"buyNowPrice\")\n",
    "                }\n",
    "                dataAll.append(item_data)\n",
    "                f.write(f'{item_data[\"title\"]}, {item_data[\"condition\"]}, {item_data[\"price\"]}\\n')\n",
    "\n",
    "        \n",
    "\n",
    "print(f\"Scraping complete. Total books collected: {len(dataAll)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c1cf7b21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>condition</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nineteen Eighty-Four</td>\n",
       "      <td>Acceptable</td>\n",
       "      <td>14.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Harry Potter and the Sorcerer's Stone</td>\n",
       "      <td>Good</td>\n",
       "      <td>7.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>To Kill a Mockingbird</td>\n",
       "      <td>Good</td>\n",
       "      <td>16.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fahrenheit 451</td>\n",
       "      <td>Good</td>\n",
       "      <td>7.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Hunger Games</td>\n",
       "      <td>Good</td>\n",
       "      <td>4.79</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   title   condition  price\n",
       "0                   Nineteen Eighty-Four  Acceptable  14.99\n",
       "1  Harry Potter and the Sorcerer's Stone        Good   7.49\n",
       "2                  To Kill a Mockingbird        Good  16.39\n",
       "3                         Fahrenheit 451        Good   7.49\n",
       "4                       The Hunger Games        Good   4.79"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(dataAll)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b601c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping page 1...\n",
      "Scraping page 2...\n",
      "Scraping complete. Total books collected: 100\n"
     ]
    }
   ],
   "source": [
    "# scrap \"Military Fiction\" books from Thriftbooks\n",
    "dataAll = []\n",
    "\n",
    "with open('Thrift_books_Data.csv', 'a', encoding='utf-8') as f:\n",
    "    f.write('Title,Condition,Price\\n')\n",
    "\n",
    "    for page in range(1, 3):  \n",
    "        url = f\"https://www.thriftbooks.com/browse/?14123col#b.s=mostPopular-desc&b.p={page}&b.pp=50&b.col&b.f.t%5B%5D=14123&b.list\"\n",
    "\n",
    "        print(f\"Scraping page {page}...\")\n",
    "\n",
    "        content = requests.get(url).content\n",
    "        soup = BeautifulSoup(content, 'html.parser')\n",
    "\n",
    "        script_content = soup.find_all('script')\n",
    "       \n",
    "        data = script_content[12].string\n",
    "        match = re.search(r'window\\.searchStoreV2\\s*=\\s*(\\{.*?\\});', data, re.DOTALL)\n",
    "\n",
    "        if match:\n",
    "            json_data = match.group(1)\n",
    "            work_json = json.loads(json_data)\n",
    "\n",
    "            works = work_json.get('works', [])\n",
    "\n",
    "            for i in works:\n",
    "                item_data = {\n",
    "                    \"title\": i.get(\"title\"),\n",
    "                    \"condition\": i.get(\"buyNowCondition\"),\n",
    "                    \"price\": i.get(\"buyNowPrice\")\n",
    "                }\n",
    "                dataAll.append(item_data)\n",
    "                f.write(f'{item_data[\"title\"]}, {item_data[\"condition\"]}, {item_data[\"price\"]}\\n')\n",
    "\n",
    "        \n",
    "\n",
    "print(f\"Scraping complete. Total books collected: {len(dataAll)}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
